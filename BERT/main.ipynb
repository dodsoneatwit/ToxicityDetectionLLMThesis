{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(data):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    result = tokenizer(str(data[\"Text\"]),truncation=True,   \n",
    "                       max_length=512, return_overflowing_tokens=True)\n",
    "\n",
    "    sample_map = result.pop(\"overflow_to_sample_mapping\")\n",
    "    for key, values in data.items():\n",
    "        result[key] = [values[i] for i in sample_map]\n",
    "    return result\n",
    "def pad_attention_mask(dataset):\n",
    "    for i in range(len(dataset)):\n",
    "        attention_mask = dataset[i]['attention_mask']\n",
    "        if len(attention_mask) < 512:\n",
    "            # Pad with zeros to reach length 512\n",
    "            padding_length = 512 - len(attention_mask)\n",
    "            dataset[i]['attention_mask'] = attention_mask + [0] * padding_length\n",
    "            # Also pad input_ids accordingly\n",
    "            dataset[i]['input_ids'] = dataset[i]['input_ids'] + [0] * padding_length\n",
    "    return dataset\n",
    "\n",
    "def process_data(dataset):\n",
    "    processed_data = []\n",
    "    for item in dataset:\n",
    "        # Assuming your dataset items are dictionaries like {'train': {'attention_mask': [...], ...}}\n",
    "        flat_item = item['train']\n",
    "        processed_data.append(flat_item)\n",
    "    return pad_attention_mask(processed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = pd.read_csv('../data/csv/processed_toxic_classification_dataset_full.csv')\n",
    "# temp = temp.dropna()\n",
    "# temp.to_csv('../data/csv/processed_toxic_classification_dataset_full_two.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"csv\", data_files=\"../data/csv/processed_toxic_classification_dataset_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text', 'Toxic'],\n",
       "    num_rows: 31909\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(tokenization,batched=True)\n",
    "\n",
    "data = data.remove_columns([\"Text\"])\n",
    "data = data.rename_column(\"Toxic\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elija\\VSCodeLocal\\Learning\\Projects\\ToxicityDetectionLLMThesis\\env\\lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"../data/models/\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    remove_unused_columns=False,  # Prevent removal of dataset columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 1031, 1005, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 3087, 3327, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 5432, 9268, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 2393, 3246, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 3436, 2147, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 1010, 1005, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 10992, 3115, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 21759, 9148, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 13642, 2276, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 3972, 12870, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3055 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  train\n",
       "0     {'labels': 0, 'input_ids': [101, 1031, 1005, 2...\n",
       "1     {'labels': 0, 'input_ids': [101, 3087, 3327, 2...\n",
       "2     {'labels': 0, 'input_ids': [101, 5432, 9268, 6...\n",
       "3     {'labels': 0, 'input_ids': [101, 2393, 3246, 2...\n",
       "4     {'labels': 0, 'input_ids': [101, 3436, 2147, 1...\n",
       "...                                                 ...\n",
       "3050  {'labels': 0, 'input_ids': [101, 1010, 1005, 7...\n",
       "3051  {'labels': 0, 'input_ids': [101, 10992, 3115, ...\n",
       "3052  {'labels': 0, 'input_ids': [101, 21759, 9148, ...\n",
       "3053  {'labels': 0, 'input_ids': [101, 13642, 2276, ...\n",
       "3054  {'labels': 0, 'input_ids': [101, 3972, 12870, ...\n",
       "\n",
       "[3055 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_data = pd.DataFrame(data)\n",
    "pandas_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 4790, 8385, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 6672, 4487, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 2071, 5993, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 1041, 12731, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 2063, 2288, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 11912, 5929, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 2451, 2015, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 22851, 11246,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 17470, 1038, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>{'labels': 0, 'input_ids': [101, 2102, 4863, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2444 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  train\n",
       "962   {'labels': 0, 'input_ids': [101, 4790, 8385, 2...\n",
       "1978  {'labels': 0, 'input_ids': [101, 6672, 4487, 5...\n",
       "351   {'labels': 0, 'input_ids': [101, 2071, 5993, 7...\n",
       "1037  {'labels': 0, 'input_ids': [101, 1041, 12731, ...\n",
       "1497  {'labels': 0, 'input_ids': [101, 2063, 2288, 5...\n",
       "...                                                 ...\n",
       "1638  {'labels': 0, 'input_ids': [101, 11912, 5929, ...\n",
       "1095  {'labels': 0, 'input_ids': [101, 2451, 2015, 1...\n",
       "1130  {'labels': 0, 'input_ids': [101, 22851, 11246,...\n",
       "1294  {'labels': 0, 'input_ids': [101, 17470, 1038, ...\n",
       "860   {'labels': 0, 'input_ids': [101, 2102, 4863, 1...\n",
       "\n",
       "[2444 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset = train_test_split(pandas_data, test_size=0.2, random_state=42)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(pd.DataFrame(train_dataset))\n",
    "val_dataset = Dataset.from_pandas(pd.DataFrame(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = process_data(train_dataset.remove_columns([\"__index_level_0__\"]))\n",
    "val_dataset = process_data(val_dataset.remove_columns([\"__index_level_0__\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'input_ids': torch.stack([torch.tensor(item['input_ids']) for item in batch]),\n",
    "        'attention_mask': torch.stack([torch.tensor(item['attention_mask']) for item in batch]),\n",
    "        'labels': torch.stack([torch.tensor(item['labels']) for item in batch]) if 'labels' in batch[0] else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3055\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "train_results = trainer.evaluate(train_dataset)\n",
    "accuracy = eval_results.get(\"eval_accuracy\", None)\n",
    "print(f\"Evaluation results: {eval_results}\")\n",
    "print(f\"Training Evaluation results: {train_results}\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128)\n",
    "    \n",
    "    # Run the model for prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    \n",
    "    # Get the predicted class\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"This is an amazing product!\",\n",
    "    \"I hate this so much. It's the worst experience ever!\",\n",
    "    \"Let's meet up for coffee tomorrow.\",\n",
    "    \"You are absolutely incompetent.\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    prediction = predict(text)\n",
    "    # label = \"Toxic\" if prediction == 1 else \"Non-Toxic\"\n",
    "    # print(f\"Text: {text}\\nPrediction: {label}\\n\")\n",
    "    print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
