{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "FINE_TUNED_TOXIC_DETECTION_API_KEY = os.getenv('FINE_TUNED_TOXIC_DETECTION_API_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc_index = os.getenv('PINECONE_GPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Pinecone vector database instance\n",
    "docSearch = Pinecone(\n",
    "    index_name=pc_index,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result = docSearch.max_marginal_relevance_search(\"Dude need chill reverting Thats point annoying\", k=3, fetch_k=50)\n",
    "# query_result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_additions(examples):\n",
    "   evaluation_prompt = ''\n",
    "   # Read the evaluation prompt from the text file with utf-8 encoding\n",
    "   with open(\"../data/text/gpt-3-5-0125-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        evaluation_prompt += file.read() \n",
    "   evaluation_prompt += '\\n\\n'\n",
    "   for example in examples:\n",
    "       evaluation_prompt += example\n",
    "\n",
    "   return evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_prompt(text):\n",
    "    two_shots = []\n",
    "    search_results = docSearch.max_marginal_relevance_search(text, k=25, fetch_k=50)\n",
    "    for i in search_results:\n",
    "        content = i.page_content\n",
    "        if i != 0 and len(content) < 50:\n",
    "            two_shots.append(content)\n",
    "    return shot_additions(two_shots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are tasked with classifying comments as either toxic or non-toxic from a non-biased viewpoint. \\nA comment is toxic if it contains harmful, abusive, or offensive language, such as threats, hate speech, \\npersonal attacks, obscene language, or discrimination. Label toxic comments with a 1 and non-toxic comments with a 0. \\n\\nMild criticism or disagreement without harmful language should be labeled as non-toxic (0). \\nUse these guidelines:\\n- Label toxic (1) if: profanity, slurs, threats, or discrimination is present.\\n- Label non-toxic (0) if: the comment is neutral, polite, or constructive, even if it expresses disagreement.\\n\\nExamples for Reference:\\n\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_prompt(\"Dude need chill reverting Thats point annoying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carioca RFA \\r\\n\\r\\nThanks for your support on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"\\r\\n\\r\\n Birthday \\r\\n\\r\\nNo worries, It's wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudoscience category? \\r\\n\\r\\nI'm assuming t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(and if such phrase exists, it would be provid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2006 (UTC)\\r\\n\\r\\n Not that any of the rest of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>\"\\r\\n\\r\\n Yay, let's all do the Pedantic Seman...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>no am not how am I supposed to Know?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>If you guys really discuss napoleon you need t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>\"\\r\\n please consider this as a personal attac...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    Geez, are you forgetful!  We've already discus...     0\n",
       "1    Carioca RFA \\r\\n\\r\\nThanks for your support on...     0\n",
       "2    \"\\r\\n\\r\\n Birthday \\r\\n\\r\\nNo worries, It's wh...     0\n",
       "3    Pseudoscience category? \\r\\n\\r\\nI'm assuming t...     0\n",
       "4    (and if such phrase exists, it would be provid...     0\n",
       "..                                                 ...   ...\n",
       "995  2006 (UTC)\\r\\n\\r\\n Not that any of the rest of...     0\n",
       "996  \"\\r\\n\\r\\n Yay, let's all do the Pedantic Seman...     0\n",
       "997               no am not how am I supposed to Know?     0\n",
       "998  If you guys really discuss napoleon you need t...     1\n",
       "999  \"\\r\\n please consider this as a personal attac...     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/csv/unprocessed_toxic_classification_dataset_short.csv')\n",
    "df['Toxic'] = df['Toxic'].apply(lambda x: str(int(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned = OpenAI(\n",
    "    api_key=FINE_TUNED_TOXIC_DETECTION_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = pd.DataFrame(columns=['Text', 'Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = ''\n",
    "# Read the evaluation prompt from the text file with utf-8 encoding\n",
    "with open(\"../data/text/gpt-3-5-0125-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    evaluation_prompt += file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are tasked with classifying comments as either toxic or non-toxic from a non-biased viewpoint. \\nA comment is toxic if it contains harmful, abusive, or offensive language, such as threats, hate speech, \\npersonal attacks, obscene language, or discrimination. Label toxic comments with a 1 and non-toxic comments with a 0. \\n\\nMild criticism or disagreement without harmful language should be labeled as non-toxic (0). \\nUse these guidelines:\\n- Label toxic (1) if: profanity, slurs, threats, or discrimination is present.\\n- Label non-toxic (0) if: the comment is neutral, polite, or constructive, even if it expresses disagreement.\\n\\nExamples for Reference:'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text = row['Text']\n",
    "    completion = fine_tuned.chat.completions.create(\n",
    "        model=\"ft:gpt-3.5-turbo-0125:personal::ANEFVZOZ\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": rag_prompt(text)\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    tuned.loc[index] = [text, completion.choices[0].message.content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carioca RFA \\r\\n\\r\\nThanks for your support on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"\\r\\n\\r\\n Birthday \\r\\n\\r\\nNo worries, It's wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudoscience category? \\r\\n\\r\\nI'm assuming t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(and if such phrase exists, it would be provid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2006 (UTC)\\r\\n\\r\\n Not that any of the rest of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>\"\\r\\n\\r\\n Yay, let's all do the Pedantic Seman...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>no am not how am I supposed to Know?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>If you guys really discuss napoleon you need t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>\"\\r\\n please consider this as a personal attac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    Geez, are you forgetful!  We've already discus...     0\n",
       "1    Carioca RFA \\r\\n\\r\\nThanks for your support on...     0\n",
       "2    \"\\r\\n\\r\\n Birthday \\r\\n\\r\\nNo worries, It's wh...     0\n",
       "3    Pseudoscience category? \\r\\n\\r\\nI'm assuming t...     0\n",
       "4    (and if such phrase exists, it would be provid...     0\n",
       "..                                                 ...   ...\n",
       "995  2006 (UTC)\\r\\n\\r\\n Not that any of the rest of...     0\n",
       "996  \"\\r\\n\\r\\n Yay, let's all do the Pedantic Seman...     0\n",
       "997               no am not how am I supposed to Know?     0\n",
       "998  If you guys really discuss napoleon you need t...     1\n",
       "999  \"\\r\\n please consider this as a personal attac...     1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = tuned['Toxic'] == df['Toxic']\n",
    "gptthreefive_original_accuracy = compare.values.sum() / compare.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "995     True\n",
       "996     True\n",
       "997     True\n",
       "998     True\n",
       "999    False\n",
       "Name: Toxic, Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.60%\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o: 97.30% with too mid-detailed evaluation prompt\n",
    "# GPT-3.5 turbo 50 set: 91.80% with summarized two-shot prompt costing 73 cents\n",
    "# GPT-3.5 turbo 200 set: 92.00% with summarized two-shot prompt costing 72 cents\n",
    "# GPT 3.5 turbo 2000 set: 97:40% with summarized two-shot prompt costing 72 cents\n",
    "print(f\"Accuracy: {gptthreefive_original_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# completion = fine_tuned.chat.completions.create(\n",
    "#     model=\"ft:gpt-4o-2024-08-06:personal::AENT6Q3Y\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"system\", \n",
    "#             \"content\": \"The user has a toxicity threshold of 1, meaning that they find 90 to 100 percent of comments non-toxic and have extremely high tolerance. Label this text as either 0 for non-toxic or 1 for toxic.\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": df['Text'][998]\n",
    "#         }\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    # Initialize the tiktoken encoder for your model\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    # Encode the prompt to get the number of tokens\n",
    "    tokens = encoding.encode(prompt)\n",
    "    return len(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
