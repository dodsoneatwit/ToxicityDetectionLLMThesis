{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports/libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary pip installation commands include:\n",
    "- pip install os\n",
    "- pip install openai\n",
    "- pip install python-dotenv\n",
    "\n",
    "#### <b>Note</b>: have a <b>.env</b> file already created for accessing API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load .env file values \n",
    "load_dotenv()\n",
    "\n",
    "# insert OpenAI API key in here from .env\n",
    "FINE_TUNED_TOXIC_DETECTION_API_KEY = os.getenv(\"FINE_TUNED_TOXIC_DETECTION_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate OpenAI client with API key\n",
    "client = OpenAI(\n",
    "    api_key=FINE_TUNED_TOXIC_DETECTION_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <b>Optional</b> for retrieving custom prompt for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = ''\n",
    "# Read the evaluation prompt from the text file with utf-8 encoding\n",
    "with open(\"../data/text/summarized_instructions.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    evaluation_prompt += file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Link to models for testing: <b>https://platform.openai.com/docs/models</b>\n",
    "\n",
    "#### Here are a few working models:\n",
    "- <b>o1-preview</b>\n",
    "- <b>o1-mini</b>\n",
    "- <b>gpt-4o-2024-08-06</b>\n",
    "- <b>gpt-4o-mini-2024-07-18</b>\n",
    "- <b>gpt-4-0613</b>\n",
    "- <b>gpt-3.5-turbo-0125</b>\n",
    "- <b>gpt-3.5-turbo-1106</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test chat bot with general model or fine-tuning model of choice\n",
    "# *model* should include available OpenAI models for evaluation from link above\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": evaluation_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"This is unacceptable. I can't believe how selfish you are!\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printed client model response results\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
