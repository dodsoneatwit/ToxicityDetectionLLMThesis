{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning increases the accuracy from 84% to 84.20%; minor change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geez forgetful Weve already discussed Marx ana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carioca RFA Thanks support request adminship f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birthday worries Enjoy ur daytalke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudoscience category Im assuming article pse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phrase exists would provided search engine eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2006 UTC rest us ever gone past 3RR good one V...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Yay lets Pedantic Semantics dance rolls eyes t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>supposed Know</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>guys really discuss napoleon need get fuckin l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>please consider personal attack user Node eu D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    Geez forgetful Weve already discussed Marx ana...     0\n",
       "1    Carioca RFA Thanks support request adminship f...     0\n",
       "2                   Birthday worries Enjoy ur daytalke     0\n",
       "3    Pseudoscience category Im assuming article pse...     0\n",
       "4    phrase exists would provided search engine eve...     0\n",
       "..                                                 ...   ...\n",
       "995  2006 UTC rest us ever gone past 3RR good one V...     0\n",
       "996  Yay lets Pedantic Semantics dance rolls eyes t...     0\n",
       "997                                      supposed Know     0\n",
       "998  guys really discuss napoleon need get fuckin l...     1\n",
       "999  please consider personal attack user Node eu D...     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/csv/processed_toxic_classification_dataset_short.csv')\n",
    "df['Toxic'] = df['Toxic'].apply(lambda x: str(int(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "FINE_TUNED_TOXIC_DETECTION_API_KEY = os.getenv('FINE_TUNED_TOXIC_DETECTION_API_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc_index = os.getenv('PINECONE_GPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned = OpenAI(\n",
    "    api_key=FINE_TUNED_TOXIC_DETECTION_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Pinecone vector database instance\n",
    "docSearch = Pinecone(\n",
    "    index_name=pc_index,\n",
    "    embedding=OpenAIEmbeddings(openai_api_key=FINE_TUNED_TOXIC_DETECTION_API_KEY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comment = \"Classify these comments as either toxic (1) non-toxic (0). Toxic comments contain offensive, harmful, or abusive language. Label 1 for toxic and 0 for non-toxic \\n\\nExamples for Reference:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = docSearch.max_marginal_relevance_search(\"please consider personal attack user Node eu Dear Node Eu take personal pride honor say commander well deserved Fuck yes know moment real identity please forgive wikipedia want assure family extend family mr Bortnikov harm intended untended occur long process well spend money involved realize finally deserve mercy Good look yes wikipedia last posting realize place muchmuch better real scientific world,0\", k=25, fetch_k=10)\n",
    "# text_one = res[1].page_content.split(' - ')\n",
    "# text_two = res[2].page_content.split(' - ')\n",
    "# text_three = res[3].page_content.split(' - ')\n",
    "# text_four = res[4].page_content.split(' - ')\n",
    "# text_five = res[5].page_content.split(' - ')\n",
    "\n",
    "# temp_comment += '\\n\\n' + 'Text: \\\"' + text_one[0] + \"\\\"\" + '\\n\\n' + text_one[1] + '\\n\\n' +'Text: \\\"' + text_two[0] + \"\\\"\" + '\\n\\n' + text_two[1] + '\\n\\n'+'Text: \\\"' + text_three[0] + \"\\\"\" + '\\n\\n' + text_three[1] + '\\n\\n' + 'Text: \\\"' + text_four[0] + \"\\\"\" + '\\n\\n' + text_four[1] + '\\n\\n' + 'Text: \\\"' + text_five[0] + \"\\\"\" + '\\n\\n' + text_five[1] +'\\n\\n' + \"Classify the following comment:\"\n",
    "# text_one\n",
    "# # ['3868. Youre seriously moron 864433121', 'Label: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/text/temp.txt', 'w') as f:\n",
    "    f.write(f\"{temp_comment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_additions(examples):\n",
    "   evaluation_prompt = ''\n",
    "   # Read the evaluation prompt from the text file with utf-8 encoding\n",
    "   with open(\"../data/text/rag_prompts/gpt-3-5-1106-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        evaluation_prompt += file.read() \n",
    "   evaluation_prompt += '\\n\\n'\n",
    "   for example in examples:\n",
    "       split_ex = example.split(' - ')\n",
    "       comment = split_ex[0]\n",
    "       label = split_ex[1]\n",
    "       evaluation_prompt += 'Text: \\\"' + comment + \"\\\"\" + '\\n\\n' + label\n",
    "\n",
    "   evaluation_prompt += '\\n\\nClassify the following comment:'\n",
    "\n",
    "   return evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_prompt(text):\n",
    "    two_shots = []\n",
    "    search_results = docSearch.max_marginal_relevance_search(text, k=25, fetch_k=50)\n",
    "    for i in search_results:\n",
    "        content = i.page_content\n",
    "        if i != 0 and len(content) < 50:\n",
    "            two_shots.append(content)\n",
    "        if len(two_shots) == 2:\n",
    "            break\n",
    "    return shot_additions(two_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = pd.DataFrame(columns=['Text', 'Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = ''\n",
    "# Read the evaluation prompt from the text file with utf-8 encoding\n",
    "with open(\"../data/text/rag_prompts/gpt-3-5-1106-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    evaluation_prompt += file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are tasked with classifying comments as either toxic or non-toxic from a non-biased viewpoint. \\nA comment is toxic if it contains harmful, abusive, or offensive language, such as threats, hate speech, \\npersonal attacks, obscene language, or discrimination. ONLY comments with a 1 for toxic or a 0 for non-toxic. \\nBelow are some examples and guidelines.\\n\\nExamples for Reference:\\n\\nText: “FUCK I\"M SO EXCITEDDDDDD.”\\n\\nLabel: 0'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text = row['Text']\n",
    "    completion = fine_tuned.chat.completions.create(\n",
    "        model=\"ft:gpt-3.5-turbo-1106:personal::AN7TvIij\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": rag_prompt(text)\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    tuned.loc[index] = [row['Text'], completion.choices[0].message.content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geez forgetful Weve already discussed Marx ana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carioca RFA Thanks support request adminship f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birthday worries Enjoy ur daytalke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudoscience category Im assuming article pse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phrase exists would provided search engine eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2006 UTC rest us ever gone past 3RR good one V...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Yay lets Pedantic Semantics dance rolls eyes t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>supposed Know</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>guys really discuss napoleon need get fuckin l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>please consider personal attack user Node eu D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    Geez forgetful Weve already discussed Marx ana...     0\n",
       "1    Carioca RFA Thanks support request adminship f...     0\n",
       "2                   Birthday worries Enjoy ur daytalke     0\n",
       "3    Pseudoscience category Im assuming article pse...     0\n",
       "4    phrase exists would provided search engine eve...     0\n",
       "..                                                 ...   ...\n",
       "995  2006 UTC rest us ever gone past 3RR good one V...     0\n",
       "996  Yay lets Pedantic Semantics dance rolls eyes t...     0\n",
       "997                                      supposed Know     0\n",
       "998  guys really discuss napoleon need get fuckin l...     1\n",
       "999  please consider personal attack user Node eu D...     1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = tuned['Toxic'] == df['Toxic']\n",
    "gptthreefive_original_accuracy = compare.values.sum() / compare.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "995     True\n",
       "996     True\n",
       "997     True\n",
       "998     True\n",
       "999    False\n",
       "Name: Toxic, Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.30%\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o: 97.30% with too mid-detailed evaluation prompt\n",
    "# GPT-3.5 turbo 50 set: 91.80% with summarized two-shot prompt costing 73 cents\n",
    "# GPT-3.5 turbo 200 set: 92.00% with summarized two-shot prompt costing 72 cents\n",
    "# GPT 3.5 turbo 2000 set: 97:30% with summarized two-shot prompt costing 72 cents\n",
    "print(f\"Accuracy: {gptthreefive_original_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# completion = fine_tuned.chat.completions.create(\n",
    "#     model=\"ft:gpt-4o-2024-08-06:personal::AENT6Q3Y\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"system\", \n",
    "#             \"content\": \"The user has a toxicity threshold of 1, meaning that they find 90 to 100 percent of comments non-toxic and have extremely high tolerance. Label this text as either 0 for non-toxic or 1 for toxic.\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": df['Text'][998]\n",
    "#         }\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
