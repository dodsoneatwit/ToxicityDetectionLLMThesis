{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "from algorithms import *\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_randomized_preprocessing(data_one, data_two):\n",
    "    data_one_pre = unintended_bias_preprocess(data_one)\n",
    "    data_two_pre = unintended_bias_preprocess(data_two)\n",
    "\n",
    "    complete_data = pd.concat([data_one_pre, data_two_pre]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    print(complete_data['Text'].isna().any())\n",
    "    return complete_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary pip installation commands include:\n",
    "- pip install pandas\n",
    "- pip install nltk\n",
    "#### <b>Note</b>: have a <b>.env</b> file already created for accessing API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading of Jigsaw Unintended Bias in Toxicity Classification datasets\n",
    "jigsaw_unintended_train = pd.read_csv('../data/secondarydatasets/UnintendedBiasInToxicityClassification/train.csv')\n",
    "jigsaw_unintended_inidividual_annotations = pd.read_csv('../data/secondarydatasets/UnintendedBiasInToxicityClassification/toxicity_individual_annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the Jigsaw Unintended Bias in Toxicity Classification dataset first: https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges datasets by 'id' column\n",
    "merged_data = pd.merge(jigsaw_unintended_train, jigsaw_unintended_inidividual_annotations, on='id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>obscene_x</th>\n",
       "      <th>identity_attack_x</th>\n",
       "      <th>insult_x</th>\n",
       "      <th>threat_x</th>\n",
       "      <th>asian</th>\n",
       "      <th>atheist</th>\n",
       "      <th>...</th>\n",
       "      <th>identity_annotator_count</th>\n",
       "      <th>toxicity_annotator_count</th>\n",
       "      <th>worker</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>identity_attack_y</th>\n",
       "      <th>insult_y</th>\n",
       "      <th>obscene_y</th>\n",
       "      <th>sexual_explicit_y</th>\n",
       "      <th>threat_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3107</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855261</th>\n",
       "      <td>6334009</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>Anyone who is quoted as having the following e...</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.621212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>740</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855262</th>\n",
       "      <td>6334010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Students defined as EBD are legally just as di...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5698</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855263</th>\n",
       "      <td>6334010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Students defined as EBD are legally just as di...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7221</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855264</th>\n",
       "      <td>6334010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Students defined as EBD are legally just as di...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15855265</th>\n",
       "      <td>6334010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Students defined as EBD are legally just as di...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15855266 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id    target  \\\n",
       "0           59848  0.000000   \n",
       "1           59848  0.000000   \n",
       "2           59848  0.000000   \n",
       "3           59848  0.000000   \n",
       "4           59849  0.000000   \n",
       "...           ...       ...   \n",
       "15855261  6334009  0.621212   \n",
       "15855262  6334010  0.000000   \n",
       "15855263  6334010  0.000000   \n",
       "15855264  6334010  0.000000   \n",
       "15855265  6334010  0.000000   \n",
       "\n",
       "                                               comment_text  severe_toxicity  \\\n",
       "0         This is so cool. It's like, 'would you want yo...         0.000000   \n",
       "1         This is so cool. It's like, 'would you want yo...         0.000000   \n",
       "2         This is so cool. It's like, 'would you want yo...         0.000000   \n",
       "3         This is so cool. It's like, 'would you want yo...         0.000000   \n",
       "4         Thank you!! This would make my life a lot less...         0.000000   \n",
       "...                                                     ...              ...   \n",
       "15855261  Anyone who is quoted as having the following e...         0.030303   \n",
       "15855262  Students defined as EBD are legally just as di...         0.000000   \n",
       "15855263  Students defined as EBD are legally just as di...         0.000000   \n",
       "15855264  Students defined as EBD are legally just as di...         0.000000   \n",
       "15855265  Students defined as EBD are legally just as di...         0.000000   \n",
       "\n",
       "          obscene_x  identity_attack_x  insult_x  threat_x  asian  atheist  \\\n",
       "0          0.000000           0.000000  0.000000       0.0    NaN      NaN   \n",
       "1          0.000000           0.000000  0.000000       0.0    NaN      NaN   \n",
       "2          0.000000           0.000000  0.000000       0.0    NaN      NaN   \n",
       "3          0.000000           0.000000  0.000000       0.0    NaN      NaN   \n",
       "4          0.000000           0.000000  0.000000       0.0    NaN      NaN   \n",
       "...             ...                ...       ...       ...    ...      ...   \n",
       "15855261   0.030303           0.045455  0.621212       0.0    NaN      NaN   \n",
       "15855262   0.000000           0.000000  0.000000       0.0    NaN      NaN   \n",
       "15855263   0.000000           0.000000  0.000000       0.0    NaN      NaN   \n",
       "15855264   0.000000           0.000000  0.000000       0.0    NaN      NaN   \n",
       "15855265   0.000000           0.000000  0.000000       0.0    NaN      NaN   \n",
       "\n",
       "          ...  identity_annotator_count  toxicity_annotator_count  worker  \\\n",
       "0         ...                         0                         4    3107   \n",
       "1         ...                         0                         4    5418   \n",
       "2         ...                         0                         4    1667   \n",
       "3         ...                         0                         4    5094   \n",
       "4         ...                         0                         4     144   \n",
       "...       ...                       ...                       ...     ...   \n",
       "15855261  ...                         0                        66     740   \n",
       "15855262  ...                         0                         4    5698   \n",
       "15855263  ...                         0                         4    7221   \n",
       "15855264  ...                         0                         4    1166   \n",
       "15855265  ...                         0                         4    1160   \n",
       "\n",
       "          toxic  severe_toxic  identity_attack_y  insult_y  obscene_y  \\\n",
       "0             0             0                  0         0          0   \n",
       "1             0             0                  0         0          0   \n",
       "2             0             0                  0         0          0   \n",
       "3             0             0                  0         0          0   \n",
       "4             0             0                  0         0          0   \n",
       "...         ...           ...                ...       ...        ...   \n",
       "15855261      1             0                  0         1          0   \n",
       "15855262      0             0                  0         0          0   \n",
       "15855263      0             0                  0         0          0   \n",
       "15855264      0             0                  0         0          0   \n",
       "15855265      0             0                  0         0          0   \n",
       "\n",
       "          sexual_explicit_y  threat_y  \n",
       "0                         0         0  \n",
       "1                         0         0  \n",
       "2                         0         0  \n",
       "3                         0         0  \n",
       "4                         0         0  \n",
       "...                     ...       ...  \n",
       "15855261                  0         0  \n",
       "15855262                  0         0  \n",
       "15855263                  0         0  \n",
       "15855264                  0         0  \n",
       "15855265                  0         0  \n",
       "\n",
       "[15855266 rows x 53 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_size = 500\n",
    "toxic_set = merged_data[merged_data['toxic'] == 1].sample(n=(evaluation_size),random_state=43)\n",
    "non_toxic_set = merged_data[merged_data['toxic'] == 0].sample(n=(evaluation_size),random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic set length: 500\n",
      "Non-Toxic set length: 500\n"
     ]
    }
   ],
   "source": [
    "# checking length of sets\n",
    "print(f\"Toxic set length: {len(toxic_set)}\")\n",
    "print(f\"Non-Toxic set length: {len(non_toxic_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# combining toxic and non-toxic sets through randomized process\n",
    "full_evaluation_set = combined_randomized_preprocessing(toxic_set, non_toxic_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves preprocessed data for late usage\n",
    "full_evaluation_set.to_csv('../data/csv/unintended_bias_toxicity_classification_set.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
