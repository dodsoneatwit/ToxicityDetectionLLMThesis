{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook tests the fine-tuned version GPT-4o to help gauge it's increase\n",
    "# in performance and compare it's results with model's original accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving API Key for fine-tuned GPT-4o model\n",
    "load_dotenv()\n",
    "FINE_TUNED_TOXIC_DETECTION_API_KEY = os.getenv('FINE_TUNED_TOXIC_DETECTION_API_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc_index = os.getenv('PINECONE_GPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Pinecone vector database instance\n",
    "docSearch = Pinecone(\n",
    "    index_name=pc_index,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating client with API key\n",
    "fine_tuned = OpenAI(\n",
    "    api_key=FINE_TUNED_TOXIC_DETECTION_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_additions(examples):\n",
    "   evaluation_prompt = ''\n",
    "   # Read the evaluation prompt from the text file with utf-8 encoding\n",
    "   with open(\"../data/text/gpt-3-5-0125-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        evaluation_prompt += file.read() \n",
    "   evaluation_prompt += '\\n\\n'\n",
    "   for example in examples:\n",
    "       evaluation_prompt += example\n",
    "\n",
    "   return evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_prompt(text):\n",
    "    two_shots = []\n",
    "    search_results = docSearch.max_marginal_relevance_search(text, k=25, fetch_k=50)\n",
    "    for i in search_results:\n",
    "        content = i.page_content\n",
    "        if i != 0 and len(content) < 50:\n",
    "            two_shots.append(content)\n",
    "    return shot_additions(two_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geez forgetful Weve already discussed Marx ana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carioca RFA Thanks support request adminship f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birthday worries Enjoy ur daytalke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudoscience category Im assuming article pse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phrase exists would provided search engine eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2006 UTC rest us ever gone past 3RR good one V...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Yay lets Pedantic Semantics dance rolls eyes t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>supposed Know</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>guys really discuss napoleon need get fuckin l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>please consider personal attack user Node eu D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    Geez forgetful Weve already discussed Marx ana...     0\n",
       "1    Carioca RFA Thanks support request adminship f...     0\n",
       "2                   Birthday worries Enjoy ur daytalke     0\n",
       "3    Pseudoscience category Im assuming article pse...     0\n",
       "4    phrase exists would provided search engine eve...     0\n",
       "..                                                 ...   ...\n",
       "995  2006 UTC rest us ever gone past 3RR good one V...     0\n",
       "996  Yay lets Pedantic Semantics dance rolls eyes t...     0\n",
       "997                                      supposed Know     0\n",
       "998  guys really discuss napoleon need get fuckin l...     1\n",
       "999  please consider personal attack user Node eu D...     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving shortened preprocessed version of kaggle toxic classification challenge dataset\n",
    "df = pd.read_csv('../data/csv/processed_toxic_classification_dataset_short.csv')\n",
    "df['Toxic'] = df['Toxic'].apply(lambda x: str(int(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renames column names\n",
    "tuned = pd.DataFrame(columns=['Text', 'Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = ''\n",
    "# Read the evaluation prompt from the text file with utf-8 encoding\n",
    "with open(\"../data/text/rag_prompts/gpt-4-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    evaluation_prompt += file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are tasked with classifying comments as either toxic or non-toxic from a non-biased viewpoint. \\nA comment is toxic if it contains harmful, abusive, or offensive language, such as threats, hate speech, \\npersonal attacks, obscene language, or discrimination. Label comments with a 1 for toxic or a 0 for non-toxic. \\nBelow are some examples and guidelines. \\n\\nMild criticism or disagreement without harmful language should be labeled as non-toxic (0). \\nUse these guidelines:\\n- Label toxic (1) if: profanity, slurs, threats, or discrimination is present.\\n- Label non-toxic (0) if: the comment is neutral, polite, or constructive, even if it expresses disagreement.\\n\\nExamples for Reference:'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing fine-tuned model across entire dataset\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Text']\n",
    "    completion = fine_tuned.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:personal::AENT6Q3Y\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": evaluation_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=10\n",
    "    )\n",
    "    tuned.loc[index] = [row['Text'], completion.choices[0].message.content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geez forgetful Weve already discussed Marx ana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carioca RFA Thanks support request adminship f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birthday worries Enjoy ur daytalke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudoscience category Im assuming article pse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phrase exists would provided search engine eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2006 UTC rest us ever gone past 3RR good one V...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Yay lets Pedantic Semantics dance rolls eyes t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>supposed Know</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>guys really discuss napoleon need get fuckin l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>please consider personal attack user Node eu D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    Geez forgetful Weve already discussed Marx ana...     0\n",
       "1    Carioca RFA Thanks support request adminship f...     0\n",
       "2                   Birthday worries Enjoy ur daytalke     0\n",
       "3    Pseudoscience category Im assuming article pse...     0\n",
       "4    phrase exists would provided search engine eve...     0\n",
       "..                                                 ...   ...\n",
       "995  2006 UTC rest us ever gone past 3RR good one V...     0\n",
       "996  Yay lets Pedantic Semantics dance rolls eyes t...     0\n",
       "997                                      supposed Know     0\n",
       "998  guys really discuss napoleon need get fuckin l...     1\n",
       "999  please consider personal attack user Node eu D...     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing results of model to dataset\n",
    "compare = tuned['Toxic'] == df['Toxic']\n",
    "gptfour_original_accuracy = compare.values.sum() / compare.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "995    True\n",
       "996    True\n",
       "997    True\n",
       "998    True\n",
       "999    True\n",
       "Name: Toxic, Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.50%\n"
     ]
    }
   ],
   "source": [
    "# fine-tuned model accuracy\n",
    "# around 97.30% with too detailed evaluation prompt\n",
    "print(f\"Accuracy: {gptfour_original_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
