{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary pip installation commands include:\n",
    "- pip install openai\n",
    "- pip install pandas\n",
    "- pip install tiktoken\n",
    "- pip install numpy\n",
    "- pip install python-dotenv\n",
    "- pip install langchain\n",
    "- pip install langchain-pinecone\n",
    "- pip install langchain-core\n",
    "- pip install langchain-openai\n",
    "\n",
    "#### <b>Note</b>: have a <b>.env</b> file already created for accessing API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving API Key from OpenAI platform\n",
    "load_dotenv()\n",
    "FINE_TUNED_TOXIC_DETECTION_API_KEY = os.getenv('FINE_TUNED_TOXIC_DETECTION_API_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc_index = os.getenv('PINECONE_GPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elija\\AppData\\Local\\Temp\\ipykernel_20320\\2326318028.py:2: LangChainDeprecationWarning: The class `Pinecone` was deprecated in LangChain 0.0.3 and will be removed in 0.3.0. Use :class:`~PineconeVectorStore` instead.\n",
      "  docSearch = Pinecone(\n"
     ]
    }
   ],
   "source": [
    "# initializing Pinecone vector database instance\n",
    "docSearch = Pinecone(\n",
    "    index_name=pc_index,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "# instantiating client with API key\n",
    "fine_tuned = OpenAI(\n",
    "    api_key=FINE_TUNED_TOXIC_DETECTION_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appends one/few shot examples to evaluation prompt\n",
    "def shot_additions(examples):\n",
    "   evaluation_prompt = ''\n",
    "   # Read the evaluation prompt from the text file with utf-8 encoding\n",
    "   with open(\"../../data/text/rag_prompts/gpt-4-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        evaluation_prompt += file.read()\n",
    "   print(f'Examples: {len(examples)}')\n",
    "   for example in examples:\n",
    "       # separates example key and values\n",
    "       split_ex = example.split(' - ')\n",
    "       comment = split_ex[0]\n",
    "       label = split_ex[1]\n",
    "       evaluation_prompt += '\\n\\nText: \\\"' + comment + \"\\\"\" + '\\n\\n' + label\n",
    "\n",
    "   evaluation_prompt += '\\n\\nClassify the following comment:'\n",
    "\n",
    "   return evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries vector database for custom,\n",
    "# with similar examples to user prompt\n",
    "def rag_prompt(text):\n",
    "    two_shots = []\n",
    "    # queries Pinecone database\n",
    "    search_results = docSearch.max_marginal_relevance_search(text, k=25, fetch_k=50)\n",
    "    print(f'Search Results Length: {len(search_results)}')\n",
    "    for i in range(len(search_results)):\n",
    "        content = search_results[i].page_content\n",
    "        # prevents repetition which will cause errors within OpenAI\n",
    "        if i != 250:\n",
    "            two_shots.append(content)\n",
    "        # two valid examples found\n",
    "        if len(two_shots) == 2:\n",
    "            print(f'Two Shots Found!')\n",
    "            break\n",
    "    return shot_additions(two_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests accuracy of chosen model against unique prompt and data\n",
    "def accuracy_testing(data, evaluation_prompt, model, use_rag = False):\n",
    "    # chooses columns of focus\n",
    "    tuned = pd.DataFrame(columns=['Text', 'Toxic'])\n",
    "    for index, row in data.iterrows():\n",
    "        text = row['Text']\n",
    "        print(f\"Index: {index}\")\n",
    "        completion = fine_tuned.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": evaluation_prompt if use_rag == False else rag_prompt(text)\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        tuned.loc[index] = [text, completion.choices[0].message.content]\n",
    "    # comparing results of model to dataset\n",
    "    compare = tuned['Toxic'] == data['Toxic']\n",
    "    accuracy = compare.values.sum() / compare.size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving datasets utilized for evaluation\n",
    "sugarai = pd.read_csv('../../data/csv/sugar_ai_toxicity_evaluation_set.csv')\n",
    "unintended_bias = pd.read_csv('../../data/csv/unintended_bias_toxicity_classification_set.csv')\n",
    "sugarai['Toxic'] = sugarai['Toxic'].apply(lambda x: str(int(x)))\n",
    "unintended_bias['Toxic'] = unintended_bias['Toxic'].apply(lambda x: str(int(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = ''\n",
    "# Read the evaluation prompt from the text file with utf-8 encoding\n",
    "with open(\"../../data/text/fine_tuned_prompts/gpt-4-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    evaluation_prompt += file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.98%\n"
     ]
    }
   ],
   "source": [
    "# testing accuracy of Sugar AI Toxicity Classification dataset on original model\n",
    "sugarai_original_test_accuracy = accuracy_testing(sugarai, \"Detect whether either is 1 for toxic or 0 for non-toxic\", \"gpt-4o\")\n",
    "print(f\"Accuracy: {sugarai_original_test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.69%\n"
     ]
    }
   ],
   "source": [
    "# testing accuracy of Sugar AI Toxicity Classification dataset on fine-tuned model\n",
    "sugarai_fine_tuned_test_accuracy = accuracy_testing(sugarai, evaluation_prompt, \"ft:gpt-4o-2024-08-06:personal::ASwKLqOH\")\n",
    "print(f\"Accuracy: {sugarai_fine_tuned_test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing accuracy of Unintended Sugar AI Toxicity Classification dataset on fine-tuned model with RAG\n",
    "sugarai_rag_tuned_test_accuracy = accuracy_testing(sugarai, evaluation_prompt, \"ft:gpt-4o-2024-08-06:personal::ASwKLqOH\", True)\n",
    "print(f\"Accuracy: {sugarai_rag_tuned_test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 69.50%\n"
     ]
    }
   ],
   "source": [
    "# testing accuracy of Unintended Bias Toxicity Classification dataset on original model\n",
    "unintended_bias_original_test_accuracy = accuracy_testing(unintended_bias, \"Detect whether either is 1 for toxic or 0 for non-toxic\", \"gpt-4o\")\n",
    "print(f\"Accuracy: {unintended_bias_original_test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.20%\n"
     ]
    }
   ],
   "source": [
    "# testing accuracy of Unintended Bias Toxicity Classification dataset on fine-tuned model\n",
    "unintended_bias_fine_tuned_test_accuracy = accuracy_testing(unintended_bias, evaluation_prompt, \"ft:gpt-4o-2024-08-06:personal::ASwKLqOH\")\n",
    "print(f\"Accuracy: {unintended_bias_fine_tuned_test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing accuracy of Unintended Bias Toxicity Classification dataset on fine-tuned model with RAG\n",
    "unintended_bias_rag_tuned_test_accuracy = accuracy_testing(unintended_bias, evaluation_prompt, \"ft:gpt-4o-2024-08-06:personal::ASwKLqOH\", True)\n",
    "print(f\"Accuracy: {unintended_bias_rag_tuned_test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving dataset utilized for evaluation\n",
    "tuned = pd.DataFrame(columns=['Text', 'Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unintended_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing fine-tuned GPT-4o model across entire dataset \n",
    "# with advanced prompting with RAG support\n",
    "# for index, row in unintended_bias.iterrows():\n",
    "#     text = row['Text']\n",
    "#     print(f\"Index: {index}\")\n",
    "#     completion = fine_tuned.chat.completions.create(\n",
    "#         model=\"ft:gpt-4o-2024-08-06:personal::ASwKLqOH\",\n",
    "#         messages=[\n",
    "#             {\n",
    "#                 \"role\": \"system\", \n",
    "#                 \"content\": rag_prompt(text)\n",
    "#             },\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": text\n",
    "#             }\n",
    "#         ]\n",
    "#     )\n",
    "#     tuned.loc[index] = [row['Text'], completion.choices[0].message.content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing results of model to dataset\n",
    "compare = tuned['Toxic'] == unintended_bias['Toxic']\n",
    "gptfour_finetuned_accuracy = compare.values.sum() / compare.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.40%\n"
     ]
    }
   ],
   "source": [
    "# fine-tuned GPT-4o model accuracy with advanced prompted engineering\n",
    "# (role prompting, two-shot examples) and RAG for few-shot support\n",
    "print(f\"Accuracy: {gptfour_finetuned_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
