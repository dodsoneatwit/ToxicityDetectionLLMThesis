{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning increases the accuracy from 84% to 84.20%; minor change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>largely written head problem put thoughts scre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unable answer question7713019517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According edits add ratings based brothers poi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take back Watch back u gwenrol whatever europe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Take care believe bullshit see Bullshit 991842...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>well know fuck idea notability fuck line make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>mane fuck souja boi nigga dont go hard n paint</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>certainly better world service called simple N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>please interact leave warnings lie talk page c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>UserAbd Muslim scum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    largely written head problem put thoughts scre...     0\n",
       "1                     unable answer question7713019517     0\n",
       "2    According edits add ratings based brothers poi...     0\n",
       "3    take back Watch back u gwenrol whatever europe...     0\n",
       "4    Take care believe bullshit see Bullshit 991842...     1\n",
       "..                                                 ...   ...\n",
       "995  well know fuck idea notability fuck line make ...     1\n",
       "996     mane fuck souja boi nigga dont go hard n paint     1\n",
       "997  certainly better world service called simple N...     0\n",
       "998  please interact leave warnings lie talk page c...     1\n",
       "999                                UserAbd Muslim scum     1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/csv/toxic_classification_evaluation_set.csv')\n",
    "df['Toxic'] = df['Toxic'].apply(lambda x: str(int(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "FINE_TUNED_TOXIC_DETECTION_API_KEY = os.getenv('FINE_TUNED_TOXIC_DETECTION_API_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc_index = os.getenv('PINECONE_GPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned = OpenAI(\n",
    "    api_key=FINE_TUNED_TOXIC_DETECTION_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Pinecone vector database instance\n",
    "docSearch = Pinecone(\n",
    "    index_name=pc_index,\n",
    "    embedding=OpenAIEmbeddings(openai_api_key=FINE_TUNED_TOXIC_DETECTION_API_KEY)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_comment = \"Classify these comments as either toxic (1) non-toxic (0). Toxic comments contain offensive, harmful, or abusive language. Label 1 for toxic and 0 for non-toxic \\n\\nExamples for Reference:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = docSearch.max_marginal_relevance_search(\"please consider personal attack user Node eu Dear Node Eu take personal pride honor say commander well deserved Fuck yes know moment real identity please forgive wikipedia want assure family extend family mr Bortnikov harm intended untended occur long process well spend money involved realize finally deserve mercy Good look yes wikipedia last posting realize place muchmuch better real scientific world,0\", k=25, fetch_k=10)\n",
    "# text_one = res[1].page_content.split(' - ')\n",
    "# text_two = res[2].page_content.split(' - ')\n",
    "# text_three = res[3].page_content.split(' - ')\n",
    "# text_four = res[4].page_content.split(' - ')\n",
    "# text_five = res[5].page_content.split(' - ')\n",
    "\n",
    "# temp_comment += '\\n\\n' + 'Text: \\\"' + text_one[0] + \"\\\"\" + '\\n\\n' + text_one[1] + '\\n\\n' +'Text: \\\"' + text_two[0] + \"\\\"\" + '\\n\\n' + text_two[1] + '\\n\\n'+'Text: \\\"' + text_three[0] + \"\\\"\" + '\\n\\n' + text_three[1] + '\\n\\n' + 'Text: \\\"' + text_four[0] + \"\\\"\" + '\\n\\n' + text_four[1] + '\\n\\n' + 'Text: \\\"' + text_five[0] + \"\\\"\" + '\\n\\n' + text_five[1] +'\\n\\n' + \"Classify the following comment:\"\n",
    "# text_one\n",
    "# # ['3868. Youre seriously moron 864433121', 'Label: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/text/temp.txt', 'w') as f:\n",
    "    f.write(f\"{temp_comment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_repetition(text):\n",
    "  \"\"\"Counts the number of repeated words in a string.\"\"\"\n",
    "\n",
    "  words = text.lower().split()\n",
    "  word_counts = Counter(words)\n",
    "  repeated_words = {word: count for word, count in word_counts.items() if count > 1}\n",
    "  for value in repeated_words:\n",
    "    if repeated_words[value] >= 25:\n",
    "      return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_additions(examples):\n",
    "   evaluation_prompt = ''\n",
    "   # Read the evaluation prompt from the text file with utf-8 encoding\n",
    "   with open(\"../../data/text/rag_prompts/gpt-3-5-0125-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        evaluation_prompt += file.read() \n",
    "   for example in examples:\n",
    "       split_ex = example.split(' - ')\n",
    "       comment = split_ex[0]\n",
    "       label = split_ex[1]\n",
    "       evaluation_prompt += '\\n\\nText: \\\"' + comment + \"\\\"\" + '\\n\\n' + label\n",
    "\n",
    "   evaluation_prompt += '\\n\\nClassify the following comment:'\n",
    "\n",
    "   return evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_prompt(text):\n",
    "    two_shots = []\n",
    "    search_results = docSearch.max_marginal_relevance_search(text, k=25, fetch_k=50)\n",
    "    for i in range(len(search_results)):\n",
    "        content = search_results[i].page_content\n",
    "        if len(content) <= 250:\n",
    "            two_shots.append(content)\n",
    "        if len(two_shots) == 2:\n",
    "            break\n",
    "    return shot_additions(two_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = pd.DataFrame(columns=['Text', 'Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = ''\n",
    "# Read the evaluation prompt from the text file with utf-8 encoding\n",
    "with open(\"../../data/text/rag_prompts/gpt-3-5-0125-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    evaluation_prompt += file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Classify these comments as either toxic (1) non-toxic (0). Toxic comments contain offensive, harmful, or abusive language. Label 1 for toxic and 0 for non-toxic\\n\\nExamples for Reference:'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text = row['Text']\n",
    "    completion = fine_tuned.chat.completions.create(\n",
    "        model=\"ft:gpt-3.5-turbo-0125:personal::ASsOrsbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": rag_prompt(text)\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    tuned.loc[index] = [row['Text'], completion.choices[0].message.content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>largely written head problem put thoughts scre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unable answer question7713019517</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>According edits add ratings based brothers poi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take back Watch back u gwenrol whatever europe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Take care believe bullshit see Bullshit 991842...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>well know fuck idea notability fuck line make ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>mane fuck souja boi nigga dont go hard n paint</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>certainly better world service called simple N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>please interact leave warnings lie talk page c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>UserAbd Muslim scum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    largely written head problem put thoughts scre...     0\n",
       "1                     unable answer question7713019517     0\n",
       "2    According edits add ratings based brothers poi...     0\n",
       "3    take back Watch back u gwenrol whatever europe...     1\n",
       "4    Take care believe bullshit see Bullshit 991842...     1\n",
       "..                                                 ...   ...\n",
       "995  well know fuck idea notability fuck line make ...     1\n",
       "996     mane fuck souja boi nigga dont go hard n paint     1\n",
       "997  certainly better world service called simple N...     0\n",
       "998  please interact leave warnings lie talk page c...     1\n",
       "999                                UserAbd Muslim scum     1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = tuned['Toxic'] == df['Toxic']\n",
    "gptthreefive_original_accuracy = compare.values.sum() / compare.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3      False\n",
       "4       True\n",
       "       ...  \n",
       "995     True\n",
       "996     True\n",
       "997     True\n",
       "998     True\n",
       "999     True\n",
       "Name: Toxic, Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.60%\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o: 97.30% with too mid-detailed evaluation prompt\n",
    "# GPT-3.5 turbo 50 set: 91.80% with summarized two-shot prompt costing 73 cents\n",
    "# GPT-3.5 turbo 200 set: 92.00% with summarized two-shot prompt costing 72 cents\n",
    "# GPT 3.5 turbo 2000 set: 97:30% with summarized two-shot prompt costing 72 cents\n",
    "print(f\"Accuracy: {gptthreefive_original_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
