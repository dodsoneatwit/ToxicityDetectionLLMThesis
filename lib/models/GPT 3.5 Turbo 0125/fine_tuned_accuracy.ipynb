{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain.schema import Document\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "FINE_TUNED_TOXIC_DETECTION_API_KEY = os.getenv('FINE_TUNED_TOXIC_DETECTION_API_KEY')\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "pc_index = os.getenv('PINECONE_GPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing Pinecone vector database instance\n",
    "docSearch = Pinecone(\n",
    "    index_name=pc_index,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_result = docSearch.max_marginal_relevance_search(\"Dude need chill reverting Thats point annoying\", k=3, fetch_k=50)\n",
    "# query_result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shot_additions(examples):\n",
    "   evaluation_prompt = ''\n",
    "   # Read the evaluation prompt from the text file with utf-8 encoding\n",
    "   with open(\"../data/text/gpt-3-5-0125-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        evaluation_prompt += file.read() \n",
    "   evaluation_prompt += '\\n\\n'\n",
    "   for example in examples:\n",
    "       evaluation_prompt += example\n",
    "\n",
    "   return evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_prompt(text):\n",
    "    two_shots = []\n",
    "    search_results = docSearch.max_marginal_relevance_search(text, k=25, fetch_k=50)\n",
    "    for i in search_results:\n",
    "        content = i.page_content\n",
    "        if i != 0 and len(content) < 50:\n",
    "            two_shots.append(content)\n",
    "    return shot_additions(two_shots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag_prompt(\"Dude need chill reverting Thats point annoying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geez forgetful Weve already discussed Marx ana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carioca RFA Thanks support request adminship f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birthday worries Enjoy ur daytalke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudoscience category Im assuming article pse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phrase exists would provided search engine eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2006 UTC rest us ever gone past 3RR good one V...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Yay lets Pedantic Semantics dance rolls eyes t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>supposed Know</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>guys really discuss napoleon need get fuckin l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>please consider personal attack user Node eu D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    Geez forgetful Weve already discussed Marx ana...     0\n",
       "1    Carioca RFA Thanks support request adminship f...     0\n",
       "2                   Birthday worries Enjoy ur daytalke     0\n",
       "3    Pseudoscience category Im assuming article pse...     0\n",
       "4    phrase exists would provided search engine eve...     0\n",
       "..                                                 ...   ...\n",
       "995  2006 UTC rest us ever gone past 3RR good one V...     0\n",
       "996  Yay lets Pedantic Semantics dance rolls eyes t...     0\n",
       "997                                      supposed Know     0\n",
       "998  guys really discuss napoleon need get fuckin l...     1\n",
       "999  please consider personal attack user Node eu D...     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/csv/processed_toxic_classification_dataset_short.csv')\n",
    "df['Toxic'] = df['Toxic'].apply(lambda x: str(int(x)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuned = OpenAI(\n",
    "    api_key=FINE_TUNED_TOXIC_DETECTION_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned = pd.DataFrame(columns=['Text', 'Toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = ''\n",
    "# Read the evaluation prompt from the text file with utf-8 encoding\n",
    "with open(\"../data/text/fine_tuned_prompts/gpt-3-5-0125-two-shot-prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    evaluation_prompt += file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Classify these comments as either toxic (1) non-toxic (0). Toxic comments contain offensive, harmful, or abusive language. Label 1 for toxic and 0 for non-toxic\\n\\nExamples for Reference:\\n\\nText: “I disagree with you, but I think you make some valid points.”\\n\\nLabel: 0\\n\\nText: “Go back to where you came from, we don’t want you here.”\\n\\nLabel: 1\\n\\nClassify the following comment:'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    text = row['Text']\n",
    "    completion = fine_tuned.chat.completions.create(\n",
    "        model=\"ft:gpt-3.5-turbo-0125:personal::ANEFVZOZ\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": evaluation_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    tuned.loc[index] = [text, completion.choices[0].message.content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geez forgetful Weve already discussed Marx ana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carioca RFA Thanks support request adminship f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birthday worries Enjoy ur daytalke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudoscience category Im assuming article pse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phrase exists would provided search engine eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2006 UTC rest us ever gone past 3RR good one V...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Yay lets Pedantic Semantics dance rolls eyes t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>supposed Know</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>guys really discuss napoleon need get fuckin l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>please consider personal attack user Node eu D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Toxic\n",
       "0    Geez forgetful Weve already discussed Marx ana...     0\n",
       "1    Carioca RFA Thanks support request adminship f...     0\n",
       "2                   Birthday worries Enjoy ur daytalke     0\n",
       "3    Pseudoscience category Im assuming article pse...     0\n",
       "4    phrase exists would provided search engine eve...     0\n",
       "..                                                 ...   ...\n",
       "995  2006 UTC rest us ever gone past 3RR good one V...     0\n",
       "996  Yay lets Pedantic Semantics dance rolls eyes t...     0\n",
       "997                                      supposed Know     0\n",
       "998  guys really discuss napoleon need get fuckin l...     1\n",
       "999  please consider personal attack user Node eu D...     1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = tuned['Toxic'] == df['Toxic']\n",
    "gptthreefive_original_accuracy = compare.values.sum() / compare.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "995     True\n",
       "996     True\n",
       "997     True\n",
       "998     True\n",
       "999    False\n",
       "Name: Toxic, Length: 1000, dtype: bool"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.70%\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o: 97.30% with too mid-detailed evaluation prompt\n",
    "# GPT-3.5 turbo 50 set: 91.80% with summarized two-shot prompt costing 73 cents\n",
    "# GPT-3.5 turbo 200 set: 92.00% with summarized two-shot prompt costing 72 cents\n",
    "# GPT 3.5 turbo 2000 set: 97:40% with summarized two-shot prompt costing 72 cents\n",
    "print(f\"Accuracy: {gptthreefive_original_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# completion = fine_tuned.chat.completions.create(\n",
    "#     model=\"ft:gpt-4o-2024-08-06:personal::AENT6Q3Y\",\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"system\", \n",
    "#             \"content\": \"The user has a toxicity threshold of 1, meaning that they find 90 to 100 percent of comments non-toxic and have extremely high tolerance. Label this text as either 0 for non-toxic or 1 for toxic.\"\n",
    "#         },\n",
    "#         {\n",
    "#             \"role\": \"user\",\n",
    "#             \"content\": df['Text'][998]\n",
    "#         }\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    # Initialize the tiktoken encoder for your model\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    # Encode the prompt to get the number of tokens\n",
    "    tokens = encoding.encode(prompt)\n",
    "    return len(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
