{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY: sk-82F0fUi3hSi_drnaRG9Z72jEbFbIqPdYHHClASd7kET3BlbkFJJqxRZ40hP-p3XxjBMCQK3qUT40AmziQLi9Vz5WIcIA\n",
    "# ORG ID: org-rjJCwF3sTsfOnw3I2Eaj4zdP\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    no_punctuation_and_specials = re.sub(r'[^\\w\\s]', '', str(data))\n",
    "    tokens = word_tokenize(str(no_punctuation_and_specials))\n",
    "    filtered_tokens = [str(word) for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119105</th>\n",
       "      <td>7ca72b5b9c688e9e</td>\n",
       "      <td>Geez, are you forgetful!  We've already discus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131631</th>\n",
       "      <td>c03f72fd8f8bf54f</td>\n",
       "      <td>Carioca RFA \\n\\nThanks for your support on my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125326</th>\n",
       "      <td>9e5b8e8fc1ff2e84</td>\n",
       "      <td>\"\\n\\n Birthday \\n\\nNo worries, It's what I do ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111256</th>\n",
       "      <td>5332799e706665a6</td>\n",
       "      <td>Pseudoscience category? \\n\\nI'm assuming that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83590</th>\n",
       "      <td>dfa7d8f0b4366680</td>\n",
       "      <td>(and if such phrase exists, it would be provid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156920</th>\n",
       "      <td>d5ab78002a95480c</td>\n",
       "      <td>I also just noticed: he simultaneously went af...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121162</th>\n",
       "      <td>8837ad52121033bc</td>\n",
       "      <td>\"  Would you claim them to be part of the \"\"ig...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34019</th>\n",
       "      <td>5ac2cc7bc20cc0cc</td>\n",
       "      <td>The lyrics is found in the German version, so ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83938</th>\n",
       "      <td>e09583af9fd6534e</td>\n",
       "      <td>Encyclopedia Titanica references do not source...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78687</th>\n",
       "      <td>d28877e35690949d</td>\n",
       "      <td>A silly fat cow who won't leave me alone</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31914 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "119105  7ca72b5b9c688e9e  Geez, are you forgetful!  We've already discus...   \n",
       "131631  c03f72fd8f8bf54f  Carioca RFA \\n\\nThanks for your support on my ...   \n",
       "125326  9e5b8e8fc1ff2e84  \"\\n\\n Birthday \\n\\nNo worries, It's what I do ...   \n",
       "111256  5332799e706665a6  Pseudoscience category? \\n\\nI'm assuming that ...   \n",
       "83590   dfa7d8f0b4366680  (and if such phrase exists, it would be provid...   \n",
       "...                  ...                                                ...   \n",
       "156920  d5ab78002a95480c  I also just noticed: he simultaneously went af...   \n",
       "121162  8837ad52121033bc  \"  Would you claim them to be part of the \"\"ig...   \n",
       "34019   5ac2cc7bc20cc0cc  The lyrics is found in the German version, so ...   \n",
       "83938   e09583af9fd6534e  Encyclopedia Titanica references do not source...   \n",
       "78687   d28877e35690949d           A silly fat cow who won't leave me alone   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "119105      0             0        0       0       0              0  \n",
       "131631      0             0        0       0       0              0  \n",
       "125326      0             0        0       0       0              0  \n",
       "111256      0             0        0       0       0              0  \n",
       "83590       0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "156920      0             0        0       0       0              0  \n",
       "121162      0             0        0       0       0              0  \n",
       "34019       0             0        0       0       0              0  \n",
       "83938       0             0        0       0       0              0  \n",
       "78687       1             0        1       0       1              0  \n",
       "\n",
       "[31914 rows x 8 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "df = df.sample(frac=0.2, random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dodsone\\AppData\\Local\\Temp\\ipykernel_19036\\259305162.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  toxic_classification['comment_text'] = toxic_classification['comment_text'].apply(preprocess)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119105</th>\n",
       "      <td>Geez forgetful Weve already discussed Marx ana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131631</th>\n",
       "      <td>Carioca RFA Thanks support request adminship f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125326</th>\n",
       "      <td>Birthday worries Enjoy ur daytalke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111256</th>\n",
       "      <td>Pseudoscience category Im assuming article pse...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83590</th>\n",
       "      <td>phrase exists would provided search engine eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68192</th>\n",
       "      <td>Recent page moves see also unresolved discussi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50285</th>\n",
       "      <td>Please stop disruptive editing vandalism conti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153486</th>\n",
       "      <td>lakes outlet sea clearly titled river Also reg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94271</th>\n",
       "      <td>dont believe need use monobook thingy done Ive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137601</th>\n",
       "      <td>Hello welcome Wikipedia Hope like stick around...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15957 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Toxic\n",
       "119105  Geez forgetful Weve already discussed Marx ana...      0\n",
       "131631  Carioca RFA Thanks support request adminship f...      0\n",
       "125326                 Birthday worries Enjoy ur daytalke      0\n",
       "111256  Pseudoscience category Im assuming article pse...      0\n",
       "83590   phrase exists would provided search engine eve...      0\n",
       "...                                                   ...    ...\n",
       "68192   Recent page moves see also unresolved discussi...      0\n",
       "50285   Please stop disruptive editing vandalism conti...      0\n",
       "153486  lakes outlet sea clearly titled river Also reg...      0\n",
       "94271   dont believe need use monobook thingy done Ive...      0\n",
       "137601  Hello welcome Wikipedia Hope like stick around...      0\n",
       "\n",
       "[15957 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_classification = df[['comment_text', 'toxic']]\n",
    "toxic_classification['comment_text'] = toxic_classification['comment_text'].apply(preprocess)\n",
    "toxic_classification.columns = ['Text', 'Toxic']\n",
    "toxic_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_json = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in toxic_classification.iterrows():\n",
    "    training_json.append({\n",
    "        \"messages\" : [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"Your job is to detect toxicity from a non-biased viewpoint and label prompted content as either toxic or non-toxic.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": row['Text']\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": str(row['Toxic'])\n",
    "            },\n",
    "        ]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7978"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "half = math.floor(len(training_json) / 2)\n",
    "half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = training_json[:half]\n",
    "validation = training_json[half + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/training_kaggle_toxic_classification_dataset.jsonl', 'w') as f:\n",
    "    for entry in training:\n",
    "        f.write(f\"{json.dumps(entry)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/validation_kaggle_toxic_classification_dataset.jsonl', 'w') as f:\n",
    "    for entry in validation:\n",
    "        f.write(f\"{json.dumps(entry)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
